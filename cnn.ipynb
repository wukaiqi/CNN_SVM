{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文件输入\n",
    "def get_files(filename):\n",
    "    class_train = []\n",
    "    label_train = []\n",
    "    for train_class in os.listdir(filename):\n",
    "        for pic in os.listdir(filename+train_class):\n",
    "            class_train.append(filename+train_class+'/'+pic)\n",
    "            label_train.append(train_class)\n",
    "    temp = np.array([class_train,label_train])\n",
    "    temp = temp.transpose()\n",
    "    #shuffle the samples\n",
    "    np.random.shuffle(temp)\n",
    "    #after transpose, images is in dimension 0 and label in dimension 1\n",
    "    image_list = list(temp[:,0])\n",
    "    label_list = list(temp[:,1])\n",
    "    label_list = [int(i) for i in label_list]\n",
    "    print(label_list)\n",
    "    return image_list,label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#产生训练队列\n",
    "def get_batches(image,label,resize_w,resize_h,batch_size,capacity):\n",
    "    #convert the list of images and labels to tensor\n",
    "    image = tf.cast(image,tf.string)\n",
    "    label = tf.cast(label,tf.int64)\n",
    "    queue = tf.train.slice_input_producer([image,label])\n",
    "    label = queue[1]\n",
    "    image_c = tf.read_file(queue[0])\n",
    "    image = tf.image.decode_jpeg(image_c,channels = 3)\n",
    "    #resize\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image,resize_w,resize_h)\n",
    "    #(x - mean) / adjusted_stddev\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    image_batch,label_batch = tf.train.batch([image,label],\n",
    "                                             batch_size = batch_size,\n",
    "                                             num_threads = 64,\n",
    "                                             capacity = capacity)\n",
    "    images_batch = tf.cast(image_batch,tf.float32)\n",
    "    labels_batch = tf.reshape(label_batch,[batch_size])\n",
    "    return images_batch,labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练模型\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,stddev = 0.01))\n",
    "#init weights\n",
    "weights = {\n",
    "    \"w1\":init_weights([5,5,3,32]),\n",
    "    \"w2\":init_weights([5,5,32,64]),\n",
    "    #\"w3\":init_weights([3,3,32,128]),\n",
    "    \"w4\":init_weights([32768,1024]),\n",
    "    \"wo\":init_weights([1024,6])\n",
    "    }\n",
    "\n",
    "#init biases\n",
    "biases = {\n",
    "    \"b1\":init_weights([32]),\n",
    "    \"b2\":init_weights([64]),\n",
    "    #\"b3\":init_weights([256]),\n",
    "    \"b4\":init_weights([1024]),\n",
    "    \"bo\":init_weights([6])\n",
    "    }\n",
    "\n",
    "# defining conv and pooling\n",
    "def conv2d(x,w,b):\n",
    "    x = tf.nn.conv2d(x,w,strides = [1,1,1,1],padding = \"SAME\")\n",
    "    x = tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def pooling(x):\n",
    "    return tf.nn.max_pool(x,ksize = [1,2,2,1],strides = [1,2,2,1],padding = \"SAME\")\n",
    "\n",
    "def norm(x,lsize = 4):\n",
    "    return tf.nn.lrn(x,depth_radius = lsize,bias = 1,alpha = 0.001/9.0,beta = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练过程\n",
    "def mmodel(images):\n",
    "    l1 = conv2d(images,weights[\"w1\"],biases[\"b1\"])\n",
    "    l2 = pooling(l1)\n",
    "    #l2 = norm(l2)\n",
    "    l3 = conv2d(l2,weights[\"w2\"],biases[\"b2\"])\n",
    "    l6 = pooling(l3)\n",
    "    #l4 = norm(l4)\n",
    "    #l5 = conv2d(l4,weights[\"w3\"],biases[\"b3\"])\n",
    "    #same as the batch size\n",
    "    #l6 = pooling(l5)\n",
    "    l6 = tf.reshape(l6,[-1,weights[\"w4\"].get_shape().as_list()[0]])\n",
    "    l7 = tf.nn.relu(tf.matmul(l6,weights[\"w4\"])+biases[\"b4\"])\n",
    "    l7 = tf.nn.dropout(l7,0.8)\n",
    "    soft_max = tf.add(tf.matmul(l7,weights[\"wo\"]),biases[\"bo\"])\n",
    "    return soft_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "def loss(logits,label_batches):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=label_batches)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义准确率\n",
    "def get_accuracy(logits,labels):\n",
    "    acc = tf.nn.in_top_k(logits,labels,1)\n",
    "    acc = tf.cast(acc,tf.float32)\n",
    "    acc = tf.reduce_mean(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练方式_网络的优化算法Optimizer\n",
    "def training(loss,lr):\n",
    "    train_op = tf.train.RMSPropOptimizer(lr,0.9).minimize(loss)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1, 2, 3, 3, 1, 5, 3, 3, 0, 0, 5, 5, 0, 0, 0, 1, 0, 5, 2, 1, 2, 2, 5, 4, 1, 4, 3, 2, 2, 5, 1, 2, 0, 1, 3, 2, 0, 0, 2, 1, 0, 4, 3, 2, 5, 0, 1, 2, 3, 5, 5, 0, 0, 4, 4, 4, 5, 0, 0, 1, 0, 4, 4, 2, 0, 5, 0, 5, 0, 2, 2, 3, 0, 2, 4, 3, 1, 4, 5, 1, 5, 0, 4, 5, 4, 4, 5, 5, 5, 0, 1, 0, 0, 2, 3, 5, 0, 2, 0, 0, 1, 0, 5, 5, 4, 2, 1, 3, 2, 4, 2, 4, 4, 2, 4, 3, 0, 0, 4, 4, 2, 4, 5, 5, 0, 3, 0, 3, 4, 0, 4, 1, 3, 1, 3, 1, 0, 1, 3, 0, 4, 2, 0, 0, 5, 1, 2, 3, 2, 4, 5, 0, 2, 4, 4, 1, 4, 5, 2, 1, 1, 5, 3, 2, 1, 3, 0, 2, 2, 1, 1, 3, 1, 0, 0, 0, 4, 1, 0, 4, 5, 0, 5, 4, 5, 5, 3, 5, 4, 3, 4, 3, 1, 0, 3, 0, 1, 2, 5, 5, 1, 1, 0, 2, 5, 0, 2, 1, 4, 3, 3, 2, 3, 5, 1, 0, 5, 1, 3, 2, 3, 5, 4, 5, 3, 3, 0, 4, 3, 4, 2, 0, 3, 3, 3, 2, 2, 3, 5, 0, 5, 3, 2, 0, 1, 3, 3, 5, 4, 2, 4, 5, 1, 2, 5, 4, 0, 0, 1, 2, 2, 0, 2, 4, 1, 0, 5, 2, 2, 5, 4, 1, 5, 5, 5, 3, 5, 2, 5, 0, 2, 2, 2, 5, 5, 3, 2, 5, 0, 5, 1, 0, 3, 1, 4, 2, 3, 3, 1, 2, 5, 3, 0, 5, 1, 3, 1, 1, 5, 1, 4, 0, 2, 1, 0, 0, 2, 5, 4, 5, 4, 3, 0, 5, 1, 5, 4, 3, 3, 5, 0, 3, 2, 1, 1, 4, 0, 0, 2, 3, 2, 3, 5, 5, 1, 5, 4, 5, 0, 1, 1, 3, 4, 0, 2, 0, 3, 3, 2, 1, 5, 4, 2, 3, 0, 5, 1, 1, 4, 0, 0, 2, 2, 4, 3, 0, 1, 3, 5, 3, 3, 3, 0, 4, 2, 5, 0, 4, 4, 1, 1, 5, 0, 5, 5, 3, 0, 3, 2, 4, 4, 0, 4, 2, 5, 1, 0, 3, 1, 1, 2, 1, 5, 1, 0, 3, 3, 0, 2, 1, 4, 4, 1, 0, 1, 4, 1, 1, 3, 4, 0, 5, 0, 5, 1, 4, 2, 1, 1, 2, 3, 0, 1, 0, 2, 5, 3, 3, 1, 4, 3, 0, 5, 0, 3, 2, 1, 1, 4, 4, 3, 5, 2, 2, 5, 2, 4, 5, 3, 3, 4, 4, 0, 0, 3, 1, 3, 2, 3, 1, 2, 2, 4, 5, 5, 0, 0, 4, 4, 3, 0, 5, 2, 4, 1, 3, 4, 1, 0, 4, 4, 0, 3, 1, 1, 1, 3, 5, 3, 4, 2, 4, 4, 4, 0, 2, 4, 0, 4, 0, 4, 5, 1, 1, 0, 2, 2, 4, 1, 1, 3, 2, 4, 3, 2, 2, 1, 3, 3, 1, 2, 1, 0, 3, 4, 3, 1, 4, 1, 5, 4, 3, 4, 3, 1, 3, 2, 3, 4, 4, 2, 2, 0, 2, 3, 0, 2, 2, 5, 0, 0, 4, 3, 0, 2, 2, 3, 4, 4, 5, 5, 4, 0, 2, 3, 0, 5, 4, 3, 1, 4, 3, 0, 5, 2, 1, 0, 2, 1, 1, 1, 4, 3, 4, 4, 1, 5, 3, 0, 2, 4, 2, 2, 0, 2, 3, 2, 5, 0, 5, 2, 0, 4, 5, 1, 4, 1, 0, 0, 0, 2, 1, 2, 3, 5, 5, 4, 4, 0, 3, 3, 1, 4, 3, 1, 1, 3, 3, 1, 4, 2, 5, 5, 5, 0, 4, 1, 5, 4, 4, 2, 3, 1, 0, 4, 4, 5, 5, 3, 2, 1, 0, 5, 3, 2, 5, 2, 2, 3, 2, 3, 3, 3, 4, 1, 5, 1, 2, 4, 0, 4, 5, 2, 2, 5, 1, 0, 3, 2, 5, 4, 0, 0, 1, 0, 3, 0, 2, 5, 4, 2, 0, 4, 5, 2, 5, 5, 5, 5, 1, 5, 4, 3, 2, 2, 0, 3, 2, 3, 0, 1, 0, 1, 1, 1, 0, 4, 3, 4, 3, 5, 3, 5, 0, 3, 4, 2, 0, 1, 1, 4, 0, 1, 3, 4, 5, 2, 1, 2, 3, 3, 1, 1, 5, 5, 5, 0, 0, 2, 1, 1, 3, 1, 4, 4, 0, 4, 5, 2, 2, 2, 1, 4, 3, 3, 5, 1, 2, 4, 1, 1, 2, 1, 1, 0, 5, 2, 5, 4, 2, 4, 2, 0, 4, 5, 2, 5, 5, 5, 0, 3, 3, 1, 1, 1, 2, 4, 5, 0, 4, 1, 2, 0, 2, 5, 2, 4, 5, 0, 0, 1, 5, 2, 5, 0, 3, 4, 1, 2, 2, 4, 1, 5, 4, 5, 0, 2, 4, 5, 3, 1, 1, 5, 3, 2, 1, 3, 4, 1, 1, 3, 0, 1, 2, 1, 2, 3, 4, 2, 5, 0, 4, 5, 1, 1, 5, 0, 2, 0, 4, 4, 4, 1, 2, 1, 4, 0, 5, 2, 2, 0, 3, 5, 2, 3, 5, 3, 1, 4, 0, 4, 3, 0, 5, 4, 5, 4, 2, 5, 2, 2, 4, 0, 1, 5, 2, 5, 5, 5, 3, 2, 4, 3, 3, 2, 2, 5, 2, 3, 1, 3, 3, 1, 4, 1, 4, 0, 3, 1, 2, 0, 3, 5, 3, 5, 1, 0, 0, 0, 3, 1, 0, 2, 5, 5, 2, 3, 5, 3, 4, 3, 4, 4, 2, 5, 2, 5, 2, 0, 1, 4, 3, 1, 4, 3, 0, 0, 2, 1, 1, 2, 5, 0, 0, 3, 2, 1, 2, 5, 0, 1, 5, 2, 1, 0, 3, 0, 4, 0, 5, 3, 0, 2, 5, 2, 0, 1, 1, 4, 4, 3, 3, 2, 3, 4, 0, 1, 3, 5, 5, 3, 0, 0, 0, 5, 3, 3, 4, 5, 4, 3, 5, 3, 3, 4, 4, 4, 3, 1, 4, 4, 2, 5, 5, 4, 1, 2, 3, 2, 5, 3, 0, 3, 3, 2, 5, 5, 1, 0, 1, 0, 2, 1, 4, 3, 0, 2, 3, 5, 4, 2, 3, 5, 4, 4, 3, 1, 0, 1, 4, 1, 4, 5, 0, 4, 1, 3, 5, 2, 1, 2, 4, 4, 2, 3, 1, 4, 4, 2, 4, 0, 3, 2, 3, 4, 3, 5, 1, 3, 0, 5, 5, 1, 1, 4, 4, 2, 3, 4, 3, 0, 2, 4, 1, 4, 1, 3, 1, 3, 5, 5, 2, 5, 1, 4, 2, 4, 5, 2, 0, 1, 3, 1, 5, 0, 0, 5, 1, 0, 4, 4, 3, 2, 2, 5, 0, 3, 1, 5, 1, 3, 5, 5, 4, 1, 4, 2, 4, 5, 2, 3, 1, 1, 1, 2, 2, 1, 0, 2, 1, 5, 5, 2, 0, 0, 4, 0, 5, 0, 4, 3, 0, 3, 0, 0, 1, 3, 3, 4]\n",
      "(20, 256, 256, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: The shape of labels (received (20,)) should equal the shape of logits except for the last dimension (received (160, 6)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-844eff44e196>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtrain_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#学习率\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a1cc979e428a>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(logits, label_batches)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#定义损失函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcross_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m   2044\u001b[0m                        \u001b[1;34m\"should equal the shape of logits except for the last \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m                        \"dimension (received %s).\" % (labels_static_shape,\n\u001b[1;32m-> 2046\u001b[1;33m                                                      logits.get_shape()))\n\u001b[0m\u001b[0;32m   2047\u001b[0m     \u001b[1;31m# Check if no reshapes are required.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2048\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape mismatch: The shape of labels (received (20,)) should equal the shape of logits except for the last dimension (received (160, 6))."
     ]
    }
   ],
   "source": [
    "#def run_training():\n",
    "\n",
    "data_dir = 'C:\\\\Users\\\\10449\\\\Desktop\\\\data\\\\'\n",
    "image,label = get_files(data_dir)\n",
    "image_batches,label_batches = get_batches(image,label,256,256,20,100)\n",
    "print(image_batches.shape)\n",
    "p = mmodel(image_batches)\n",
    "cost = loss(p,label_batches)\n",
    "train_op = training(cost,0.0001)#学习率\n",
    "acc = get_accuracy(p,label_batches)\n",
    " \n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess = sess,coord = coord)\n",
    "    \n",
    "try:\n",
    "    for step in np.arange(12000):\n",
    "        print(step)\n",
    "        if coord.should_stop():\n",
    "            break\n",
    "        _,train_acc,train_loss = sess.run([train_op,acc,cost])\n",
    "        print(\"loss:{} accuracy:{}\".format(train_loss,train_acc))\n",
    "        if step % 100 == 0:\n",
    "            check = os.path.join(log_dir,\"model.ckpt\")\n",
    "            saver.save(sess,check,global_step = step)\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print(\"Done!!!\")\n",
    "finally:\n",
    "    coord.request_stop()\n",
    "coord.join(threads)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
